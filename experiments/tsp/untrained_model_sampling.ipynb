{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9841cfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.utils.framework import try_import_tf\n",
    "tf1, tf, tfv = try_import_tf()\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f177b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from graphenv.examples.tsp.graph_utils import make_complete_planar_graph\n",
    "from graphenv.graph_env import GraphEnv\n",
    "from graphenv.examples.tsp.tsp_nfp_state import TSPNFPState\n",
    "from graphenv.examples.tsp.tsp_nfp_model import TSPGNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fa0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40\n",
    "G = make_complete_planar_graph(N=N, seed=0)\n",
    "\n",
    "tsp_nfp_state = TSPNFPState(G, max_num_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19539a5d",
   "metadata": {},
   "source": [
    "## Check the greedy search heuristic baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51209ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Networkx greedy reward: -5.987\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.approximation.traveling_salesman import greedy_tsp\n",
    "tsp_approx = nx.approximation.traveling_salesman_problem\n",
    "\n",
    "path = tsp_approx(G, cycle=True, method=greedy_tsp)\n",
    "reward_baseline = -sum([G[path[i]][path[i + 1]][\"weight\"] for i in range(0, N)])\n",
    "print(f\"Networkx greedy reward: {reward_baseline:1.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b06f31",
   "metadata": {},
   "source": [
    "## Initialize a model without any trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6125244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphEnv({\n",
    "    \"state\": tsp_nfp_state,\n",
    "    \"max_num_children\": G.number_of_nodes(),\n",
    "})\n",
    "\n",
    "model = TSPGNNModel._create_base_model(num_messages=1, embed_dim=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b0a40",
   "metadata": {},
   "source": [
    "## Sample from the model's logit value predictions with a softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3236035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model():\n",
    "    \n",
    "    env.reset()\n",
    "    obs = env.make_observation()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        values = model(obs['vertex_observations'])[0]\n",
    "        masked_action_values = tf.where(\n",
    "            obs['action_mask'][1:], values[1:, 0], values.dtype.min\n",
    "        )\n",
    "        action_probabilities = tf.nn.softmax(masked_action_values).numpy()\n",
    "        action = np.random.choice(env.max_num_children, size=1, p=action_probabilities)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0184235b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e37cd7fe80d4ba3b41b2d8e347b2984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[-7.606531147266801,\n",
       " -6.833060707694988,\n",
       " -7.946361488918026,\n",
       " -7.78510613142895,\n",
       " -6.698088958210221,\n",
       " -7.476044846218038,\n",
       " -6.894692868352494,\n",
       " -7.568217203405193,\n",
       " -7.955649206270243,\n",
       " -8.039583309734674]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sample_model() for _ in tqdm(range(10))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1cc9a1",
   "metadata": {},
   "source": [
    "## Create rllib agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17f314bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:51:35,918\tINFO services.py:1374 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/pstjohn/mambaforge/envs/graphenv/lib/python3.9/site-packages/ray/dashboard/agent.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   if LooseVersion(aiohttp.__version__) < LooseVersion(\"4.0.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19213)\u001b[0m WARNING:tensorflow:5 out of the last 6 calls to <function _ at 0x7ed20c78e5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19213)\u001b[0m WARNING:tensorflow:6 out of the last 7 calls to <function _ at 0x7ed20c78e5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=19213)\u001b[0m 2022-05-11 14:51:44,177\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function _ at 0x7f2732466b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function _ at 0x7f2732466b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 14:51:44,753\tINFO trainable.py:125 -- Trainable.setup took 11.866 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-05-11 14:51:44,754\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "\n",
    "ModelCatalog.register_custom_model('TSPGNNModel', TSPGNNModel)\n",
    "register_env('GraphEnv', lambda config: GraphEnv(config))\n",
    "\n",
    "config = {\n",
    "    \"env\": 'GraphEnv',\n",
    "    \"env_config\": {\n",
    "        \"state\": tsp_nfp_state,\n",
    "        \"max_num_children\": G.number_of_nodes(),\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"custom_model\": 'TSPGNNModel',\n",
    "        \"custom_model_config\": {\"num_messages\": 1, \"embed_dim\": 32},\n",
    "    },\n",
    "    \"num_workers\": 1,\n",
    "    \"num_gpus\": 0,\n",
    "    \"framework\": \"tf2\",\n",
    "    \"eager_tracing\": True,\n",
    "}\n",
    "\n",
    "\n",
    "from ray.rllib.agents import ppo\n",
    "\n",
    "\n",
    "\n",
    "ppo_config = ppo.DEFAULT_CONFIG.copy()\n",
    "ppo_config.update(config)\n",
    "agent = ppo.PPOTrainer(config=ppo_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cca7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphEnv({\n",
    "        \"state\": tsp_nfp_state,\n",
    "        \"max_num_children\": G.number_of_nodes(),\n",
    "    })\n",
    "\n",
    "def sample_ppo_action():\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "\n",
    "    while not done:\n",
    "        action = agent.compute_single_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        \n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de820037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd9849637734ff08390c78c2b3a9f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[-6.7207132466504875,\n",
       " -7.145118287632355,\n",
       " -7.131609371651683,\n",
       " -7.388476603609273,\n",
       " -7.731130821575868,\n",
       " -8.0216944128351,\n",
       " -7.149810385352723,\n",
       " -7.355950309062479,\n",
       " -6.950356959883898,\n",
       " -7.44635546527844]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/pstjohn/mambaforge/envs/graphenv/lib/python3.9/site-packages/ray/dashboard/agent.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   if LooseVersion(aiohttp.__version__) < LooseVersion(\"4.0.0\"):\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/pstjohn/mambaforge/envs/graphenv/lib/python3.9/site-packages/ray/dashboard/agent.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   if LooseVersion(aiohttp.__version__) < LooseVersion(\"4.0.0\"):\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/pstjohn/mambaforge/envs/graphenv/lib/python3.9/site-packages/ray/dashboard/agent.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   if LooseVersion(aiohttp.__version__) < LooseVersion(\"4.0.0\"):\n"
     ]
    }
   ],
   "source": [
    "[sample_ppo_action() for _ in tqdm(range(10))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
