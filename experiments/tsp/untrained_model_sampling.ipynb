{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9841cfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.utils.framework import try_import_tf\n",
    "tf1, tf, tfv = try_import_tf()\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f177b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from graphenv.examples.tsp.graph_utils import make_complete_planar_graph\n",
    "from graphenv.graph_env import GraphEnv\n",
    "from graphenv.examples.tsp.tsp_nfp_state import TSPNFPState\n",
    "from graphenv.examples.tsp.tsp_nfp_model import TSPGNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fa0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40\n",
    "\n",
    "tsp_nfp_state = TSPNFPState(lambda: make_complete_planar_graph(N), max_num_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19539a5d",
   "metadata": {},
   "source": [
    "## Check the greedy search heuristic baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51209ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Networkx greedy reward: -6.065\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.approximation.traveling_salesman import greedy_tsp\n",
    "tsp_approx = nx.approximation.traveling_salesman_problem\n",
    "\n",
    "G = make_complete_planar_graph(N)\n",
    "path = tsp_approx(G, cycle=True, method=greedy_tsp)\n",
    "reward_baseline = -sum([G[path[i]][path[i + 1]][\"weight\"] for i in range(0, N)])\n",
    "print(f\"Networkx greedy reward: {reward_baseline:1.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b06f31",
   "metadata": {},
   "source": [
    "## Initialize a model without any trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6125244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphEnv({\n",
    "    \"state\": tsp_nfp_state,\n",
    "    \"max_num_children\": G.number_of_nodes(),\n",
    "})\n",
    "\n",
    "model = TSPGNNModel._create_base_model(num_messages=1, embed_dim=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b0a40",
   "metadata": {},
   "source": [
    "## Sample from the model's logit value predictions with a softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3236035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model():\n",
    "    \n",
    "    env.reset()\n",
    "    obs = env.make_observation()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        values = model(obs['vertex_observations'])[0]\n",
    "        masked_action_values = tf.where(\n",
    "            obs['action_mask'][1:], values[1:, 0], values.dtype.min\n",
    "        )\n",
    "        action_probabilities = tf.nn.softmax(masked_action_values).numpy()\n",
    "        action = np.random.choice(env.max_num_children, size=1, p=action_probabilities)[0]\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0184235b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7615125fec5c4c9c94cd6c81854f3d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[-7.670711860667094,\n",
       " -8.255356356799277,\n",
       " -8.231026465888045,\n",
       " -7.671346259475466,\n",
       " -8.335099720680878,\n",
       " -7.620007661195499,\n",
       " -7.433247461280753,\n",
       " -8.283621356137186,\n",
       " -7.445996696252394,\n",
       " -7.3782104001350906]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sample_model() for _ in tqdm(range(10))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1cc9a1",
   "metadata": {},
   "source": [
    "## Create rllib agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f72a38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "env.observation_space.contains(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d7236f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space['action_mask'].contains(obs['action_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e526eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in env.observation_space['vertex_observations'].keys():\n",
    "    assert env.observation_space['vertex_observations'][key].contains(obs['vertex_observations'][key]), key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43dd42de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 200, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space['vertex_observations']['connectivity'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993cbe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 200, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs['vertex_observations']['connectivity'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17f314bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 08:15:42,192\tINFO services.py:1374 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/pstjohn/mambaforge/envs/graphenv/lib/python3.9/site-packages/ray/dashboard/agent.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   if LooseVersion(aiohttp.__version__) < LooseVersion(\"4.0.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27578)\u001b[0m WARNING:tensorflow:5 out of the last 6 calls to <function _ at 0x7fb3c2edb5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27578)\u001b[0m WARNING:tensorflow:6 out of the last 7 calls to <function _ at 0x7fb3c2edb5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=27578)\u001b[0m 2022-05-18 08:15:50,815\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function _ at 0x7f1603243ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function _ at 0x7f1603243ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 08:15:51,353\tINFO trainable.py:125 -- Trainable.setup took 12.115 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-05-18 08:15:51,354\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "\n",
    "ModelCatalog.register_custom_model('TSPGNNModel', TSPGNNModel)\n",
    "register_env('GraphEnv', lambda config: GraphEnv(config))\n",
    "\n",
    "config = {\n",
    "    \"env\": 'GraphEnv',\n",
    "    \"env_config\": {\n",
    "        \"state\": tsp_nfp_state,\n",
    "        \"max_num_children\": G.number_of_nodes(),\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"custom_model\": 'TSPGNNModel',\n",
    "        \"custom_model_config\": {\"num_messages\": 1, \"embed_dim\": 32},\n",
    "    },\n",
    "    \"num_workers\": 1,\n",
    "    \"num_gpus\": 0,\n",
    "    \"framework\": \"tf2\",\n",
    "    \"eager_tracing\": True,\n",
    "}\n",
    "\n",
    "\n",
    "from ray.rllib.agents import ppo\n",
    "\n",
    "\n",
    "\n",
    "ppo_config = ppo.DEFAULT_CONFIG.copy()\n",
    "ppo_config.update(config)\n",
    "agent = ppo.PPOTrainer(config=ppo_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cca7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GraphEnv({\n",
    "        \"state\": tsp_nfp_state,\n",
    "        \"max_num_children\": G.number_of_nodes(),\n",
    "    })\n",
    "\n",
    "def sample_ppo_action():\n",
    "    # run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs, info = env.reset()\n",
    "\n",
    "    while not done:\n",
    "        action = agent.compute_single_action(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        episode_reward += reward\n",
    "        \n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de820037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6d81ecb0fd4449b249a58dd7a54fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[-7.470961114058433,\n",
       " -6.770144662767127,\n",
       " -7.407155430808889,\n",
       " -8.720809002028735,\n",
       " -7.265972881233817,\n",
       " -7.404054532323574,\n",
       " -8.361671640332627,\n",
       " -7.584063264209201,\n",
       " -8.228413557010217,\n",
       " -6.924827091584273]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/pstjohn/mambaforge/envs/graphenv/lib/python3.9/site-packages/ray/dashboard/agent.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   if LooseVersion(aiohttp.__version__) < LooseVersion(\"4.0.0\"):\n",
      "2022-05-18 08:16:02,630\tERROR worker.py:488 -- print_logs: Connection closed by server.\n",
      "2022-05-18 08:16:02,631\tERROR import_thread.py:83 -- ImportThread: Connection closed by server.\n",
      "2022-05-18 08:16:02,639\tERROR worker.py:1259 -- listen_error_messages_raylet: Connection closed by server.\n",
      "*** SIGTERM received at time=1652883364 on cpu 5 ***\n",
      "PC: @     0x7f175c8f1eb3  (unknown)  epoll_wait\n",
      "    @     0x7f175d4e1630  (unknown)  (unknown)\n",
      "[2022-05-18 08:16:04,917 E 27227 27227] logging.cc:317: *** SIGTERM received at time=1652883364 on cpu 5 ***\n",
      "[2022-05-18 08:16:04,917 E 27227 27227] logging.cc:317: PC: @     0x7f175c8f1eb3  (unknown)  epoll_wait\n",
      "[2022-05-18 08:16:04,917 E 27227 27227] logging.cc:317:     @     0x7f175d4e1630  (unknown)  (unknown)\n"
     ]
    }
   ],
   "source": [
    "[sample_ppo_action() for _ in tqdm(range(10))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
